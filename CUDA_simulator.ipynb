{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMAcEusWa377VDjpeCRJcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshulsawant/llm-systems/blob/main/CUDA_simulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ovnlWerSVhG5"
      },
      "outputs": [],
      "source": [
        "import numba\n",
        "import os\n",
        "# os.environ['NUMBA_ENABLE_CUDASIM'] = '1'\n",
        "import numpy as np\n",
        "from numba import cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def vec_add(A, B, n, out):\n",
        "    x = cuda.threadIdx.x\n",
        "    bx = cuda.blockIdx.x\n",
        "    bdx = cuda.blockDim.x\n",
        "    i = bx * bdx + x\n",
        "    if i < n:\n",
        "      out[i] = A[i] + B[i]"
      ],
      "metadata": {
        "id": "vVDLI42_VpCe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 14\n",
        "A = np.arange(n)\n",
        "B = np.ones_like(A)\n",
        "C = np.zeros_like(A)"
      ],
      "metadata": {
        "id": "8p4N4kZlWYMP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "griddim = 4\n",
        "blockdim = 4\n",
        "vec_add[griddim, blockdim](A, B, n, C)\n",
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1q6ukcbXk-M",
        "outputId": "7badef22-7cd7-4506-e384-8e34e98fb403"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_position(index, strides, num_dims):\n",
        "    '''\n",
        "     Converts a multidimensional tensor index into a single-dimensional position in storage\n",
        "     based on strides.\n",
        "     Args:\n",
        "        index: index tuple of ints\n",
        "        strides: tensor strides\n",
        "        num_dims: number of dimensions in the tensor, e.g. shape/strides of [2, 3, 4] has 3 dimensions\n",
        "\n",
        "     Returns:\n",
        "        int - position in storage\n",
        "    '''\n",
        "    position = 0;\n",
        "    for i in range(num_dims):\n",
        "        position += index[i] * strides[i];\n",
        "    return position;\n",
        "\n",
        "def to_index(ordinal, shape, out_index, num_dims):\n",
        "    '''\n",
        "     Convert an ordinal to an index in the shape. Should ensure that enumerating position 0 ... size of\n",
        "     a tensor produces every index exactly once. It may not be the inverse of index_to_position.\n",
        "     Args:\n",
        "        ordinal: ordinal position to convert\n",
        "        shape: tensor shape\n",
        "        out_index: return index corresponding to position\n",
        "        num_dims: number of dimensions in the tensor\n",
        "\n",
        "     Returns:\n",
        "        None (Fills in out_index)\n",
        "    '''\n",
        "    cur_ord = ordinal;\n",
        "    for i in reversed(range(num_dims)):\n",
        "        sh = shape[i];\n",
        "        out_index[i] = cur_ord % sh;\n",
        "        cur_ord /= sh;\n",
        "\n",
        "def broadcast_index(big_index, big_shape, shape, out_index, num_dims_big, num_dims):\n",
        "    '''\n",
        "     Convert a big_index into big_shape to a smaller out_index into shape following broadcasting rules.\n",
        "     In this case it may be larger or with more dimensions than the shape given.\n",
        "     Additional dimensions may need to be mapped to 0 or removed.\n",
        "\n",
        "     Args:\n",
        "        big_index: multidimensional index of bigger tensor\n",
        "        big_shape: tensor shape of bigger tensor\n",
        "        nums_big_dims: number of dimensions in bigger tensor\n",
        "        out_index: multidimensional index of smaller tensor\n",
        "        shape: tensor shape of smaller tensor\n",
        "        num_dims: number of dimensions in smaller tensor\n",
        "\n",
        "     Returns:\n",
        "        None (Fills in out_index)\n",
        "    '''\n",
        "    for i in range(num_dims):\n",
        "        if shape[i] > 1:\n",
        "            out_index[i] = big_index[i + (num_dims_big - num_dims)]\n",
        "        else:\n",
        "            out_index[i] = 0\n"
      ],
      "metadata": {
        "id": "2iBo38geZqsV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}