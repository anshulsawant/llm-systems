{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshulsawant/llm-systems/blob/main/cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b34981f1-9278-4ee8-a2de-57c6245041a7",
      "metadata": {
        "id": "b34981f1-9278-4ee8-a2de-57c6245041a7"
      },
      "source": [
        "# Getting started with CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fce84e-7b13-446e-9504-eb037dc26d03",
      "metadata": {
        "id": "21fce84e-7b13-446e-9504-eb037dc26d03"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "f92d55a1-7ded-4a1d-9615-4e12b7084134",
      "metadata": {
        "id": "f92d55a1-7ded-4a1d-9615-4e12b7084134"
      },
      "outputs": [],
      "source": [
        "import torch, os, math\n",
        "import torchvision as tv\n",
        "import torchvision.transforms.functional as tvf\n",
        "from torchvision import io\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.cpp_extension import load_inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wurlitzer ninja"
      ],
      "metadata": {
        "id": "5B5oCmdTC0Io",
        "outputId": "30f92acf-7075-41fb-dcc5-d845c18aa004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5B5oCmdTC0Io",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9fa891f-fc66-4467-8ec7-9f075e363d73",
      "metadata": {
        "id": "d9fa891f-fc66-4467-8ec7-9f075e363d73"
      },
      "source": [
        "### Python Block Kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d149f7-3e31-42ee-a4ff-27f0e03919a1",
      "metadata": {
        "id": "57d149f7-3e31-42ee-a4ff-27f0e03919a1"
      },
      "source": [
        "1. **Streaming Multiprocessors (SMs):** In NVIDIA GPUs, SMs are the fundamental units of execution. Each SM can execute multiple threads concurrently.\n",
        "2. **Thread Blocks:** A thread block is a group of threads that can cooperate among themselves through shared memory and synchronization. All threads in a block are executed on the same SM. This means they can share resources such as shared memory and can synchronize their execution with each other.\n",
        "3. **Shared Memory:** Shared memory is a small memory space on the GPU that is shared among the threads in a block. It is much faster than global memory (the main GPU memory), but it is also limited in size. Threads in the same block can use shared memory to share data with each other efficiently.\n",
        "\n",
        "- The RTX 3090, based on the Ampere architecture, has 82 SMs.\n",
        "- Each SM in GA10x GPUs contain 128 CUDA Cores, four third-generation Tensor Cores, a 256 KB Register File, and 128 KB of L1/Shared Memory\n",
        "- In CUDA, all threads in a block have the potential to run concurrently. However, the actual concurrency depends on the number of CUDA cores per SM and the resources required by the threads."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce90684-6133-477c-b71e-30815dfeb393",
      "metadata": {
        "id": "7ce90684-6133-477c-b71e-30815dfeb393"
      },
      "source": [
        "### CUDA Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "27d5004d-6e4b-494f-8be0-30514e17f539",
      "metadata": {
        "id": "27d5004d-6e4b-494f-8be0-30514e17f539"
      },
      "outputs": [],
      "source": [
        "## This is slow but good for dev.\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "e95a2197-a06f-47ee-916d-04a6928199bb",
      "metadata": {
        "id": "e95a2197-a06f-47ee-916d-04a6928199bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99869447-a01b-47fa-c911-be51bd86db3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The wurlitzer extension is already loaded. To reload it, use:\n",
            "  %reload_ext wurlitzer\n"
          ]
        }
      ],
      "source": [
        "%load_ext wurlitzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "4d22883b-477a-4560-be1e-e51448ca2e25",
      "metadata": {
        "id": "4d22883b-477a-4560-be1e-e51448ca2e25"
      },
      "outputs": [],
      "source": [
        "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                       extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name=\"inline_ext\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "6dbaa081-ad95-404b-ad93-0a4358bf450b",
      "metadata": {
        "id": "6dbaa081-ad95-404b-ad93-0a4358bf450b"
      },
      "outputs": [],
      "source": [
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e79577e-2bd0-4bc7-98d7-c37d2594d14d",
      "metadata": {
        "id": "1e79577e-2bd0-4bc7-98d7-c37d2594d14d"
      },
      "source": [
        "<img src=\"attachment:4590626e-3f24-4381-a14b-50162f737579.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd968fbe-60df-4644-ac31-2099ee8207d7",
      "metadata": {
        "id": "dd968fbe-60df-4644-ac31-2099ee8207d7"
      },
      "source": [
        "## Matmul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "b14b9d40-e252-424a-9d44-f7cea3fcdfb4",
      "metadata": {
        "id": "b14b9d40-e252-424a-9d44-f7cea3fcdfb4"
      },
      "outputs": [],
      "source": [
        "from torch import tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27dd979-a35d-43a8-9b72-9918a2f7fb6c",
      "metadata": {
        "id": "e27dd979-a35d-43a8-9b72-9918a2f7fb6c"
      },
      "source": [
        "### Python matmul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "eb141f6e-9813-44cc-b153-ccad49347648",
      "metadata": {
        "id": "eb141f6e-9813-44cc-b153-ccad49347648",
        "outputId": "4f6b4d9f-964d-4758-804d-5d6b3d96a8d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "m1 = torch.randn(5, 784)\n",
        "m2 = torch.randn(784, 10)\n",
        "m1.shape,m2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "fac45192-62e2-4245-b0aa-a4ba00e3f47f",
      "metadata": {
        "id": "fac45192-62e2-4245-b0aa-a4ba00e3f47f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2, linewidth=140)\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ac4099-e90d-4f19-a6e2-a24df81c9739",
      "metadata": {
        "id": "b4ac4099-e90d-4f19-a6e2-a24df81c9739"
      },
      "source": [
        "### 2d Python kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "434e5f38-5da2-4bac-9d95-e9d2b2042ff2",
      "metadata": {
        "id": "434e5f38-5da2-4bac-9d95-e9d2b2042ff2"
      },
      "outputs": [],
      "source": [
        "from types import SimpleNamespace as ns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "2ef592ed-b605-46f5-b72d-662ab46a55e8",
      "metadata": {
        "id": "2ef592ed-b605-46f5-b72d-662ab46a55e8"
      },
      "outputs": [],
      "source": [
        "def blk_kernel2d(f, blocks, threads, *args):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            for j0 in range(threads.y):\n",
        "                for j1 in range(threads.x): f(ns(x=i1,y=i0), ns(x=j1,y=j0), threads, *args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "62f8923f-8072-4f52-a644-6576f7dfe352",
      "metadata": {
        "id": "62f8923f-8072-4f52-a644-6576f7dfe352"
      },
      "outputs": [],
      "source": [
        "def matmul_bk(blockidx, threadidx, blockdim, m, n, out, h, w, k):\n",
        "    r = blockidx.y*blockdim.y + threadidx.y\n",
        "    c = blockidx.x*blockdim.x + threadidx.x\n",
        "\n",
        "    if (r>=h or c>=w): return\n",
        "    o = 0.\n",
        "    for i in range(k): o += m[r*k+i] * n[i*w+c]\n",
        "    out[r*w+c] = o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "a53c2202-1169-4ac6-a477-82b82f3c5201",
      "metadata": {
        "id": "a53c2202-1169-4ac6-a477-82b82f3c5201"
      },
      "outputs": [],
      "source": [
        "def matmul_2d(m, n):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = ns(x=16,y=16)\n",
        "    blocks = ns(x=math.ceil(w/tpb.x), y=math.ceil(h/tpb.y))\n",
        "    blk_kernel2d(matmul_bk, blocks, tpb,\n",
        "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "dc868ac2-7e60-4a1e-8bba-b40e452b6ef9",
      "metadata": {
        "id": "dc868ac2-7e60-4a1e-8bba-b40e452b6ef9",
        "outputId": "36af4c99-76ab-4839-e075-5c492fead0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "res = matmul_2d(m1, m2)\n",
        "torch.isclose(t1, res).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "903ab09b-bb28-47c2-9c82-94863056c149",
      "metadata": {
        "id": "903ab09b-bb28-47c2-9c82-94863056c149"
      },
      "source": [
        "### Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "7b52029b-8570-4557-b162-d400f5b669d4",
      "metadata": {
        "id": "7b52029b-8570-4557-b162-d400f5b669d4"
      },
      "outputs": [],
      "source": [
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar): c[i] = (a[i,:,None] * b).sum(dim=0)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "10e2bda8-4823-459a-b618-82b9b20c8308",
      "metadata": {
        "id": "10e2bda8-4823-459a-b618-82b9b20c8308",
        "outputId": "2cc6fb3c-dbf1-42c5-bca5-65a178a727ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "torch.isclose(t1,matmul(m1, m2)).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "f4bbd2b4-b79a-41fe-a3de-ecb0673503b3",
      "metadata": {
        "id": "f4bbd2b4-b79a-41fe-a3de-ecb0673503b3",
        "outputId": "2254647e-26a0-42f0-c9b9-d0b04bd153e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.82 ms, sys: 0 ns, total: 1.82 ms\n",
            "Wall time: 1.57 ms\n"
          ]
        }
      ],
      "source": [
        "%time _=matmul(m1, m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "88649ae9-4056-450f-bdfa-4d30a7183248",
      "metadata": {
        "id": "88649ae9-4056-450f-bdfa-4d30a7183248",
        "outputId": "eca75328-fcb3-4dd0-f088-e60e17916fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "m1 = x_train\n",
        "tr = matmul(m1, m2)\n",
        "tr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "3a5dffcd-1cfd-423e-9e71-e83e59a7dca3",
      "metadata": {
        "id": "3a5dffcd-1cfd-423e-9e71-e83e59a7dca3",
        "outputId": "ba0fd059-8581-4c01-fc97-67091035e826",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.26 s, sys: 5.21 ms, total: 1.27 s\n",
            "Wall time: 1.27 s\n"
          ]
        }
      ],
      "source": [
        "%time _=matmul(m1, m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "d84742e1-4094-433d-97bd-7932482a63c1",
      "metadata": {
        "id": "d84742e1-4094-433d-97bd-7932482a63c1",
        "outputId": "9a5ac493-9b6c-4684-8b63-a00735086221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392000000"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "ar,ac = m1.shape\n",
        "br,bc = m2.shape\n",
        "ar*bc*ac"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_position(index, strides, num_dims):\n",
        "    '''\n",
        "     Converts a multidimensional tensor index into a single-dimensional position in storage\n",
        "     based on strides.\n",
        "     Args:\n",
        "        index: index tuple of ints\n",
        "        strides: tensor strides\n",
        "        num_dims: number of dimensions in the tensor, e.g. shape/strides of [2, 3, 4] has 3 dimensions\n",
        "\n",
        "     Returns:\n",
        "        int - position in storage\n",
        "    '''\n",
        "    position = 0;\n",
        "    for i in range(num_dims):\n",
        "        position += index[i] * strides[i];\n",
        "    return position;\n",
        "\n",
        "def to_index(ordinal, shape, out_index, num_dims):\n",
        "    '''\n",
        "     Convert an ordinal to an index in the shape. Should ensure that enumerating position 0 ... size of\n",
        "     a tensor produces every index exactly once. It may not be the inverse of index_to_position.\n",
        "     Args:\n",
        "        ordinal: ordinal position to convert\n",
        "        shape: tensor shape\n",
        "        out_index: return index corresponding to position\n",
        "        num_dims: number of dimensions in the tensor\n",
        "\n",
        "     Returns:\n",
        "        None (Fills in out_index)\n",
        "    '''\n",
        "    cur_ord = ordinal;\n",
        "    for i in reversed(range(num_dims)):\n",
        "        sh = shape[i];\n",
        "        out_index[i] = cur_ord % sh;\n",
        "        cur_ord /= sh;\n",
        "\n",
        "def broadcast_index(big_index, big_shape, shape, out_index, num_dims_big, num_dims):\n",
        "    '''\n",
        "     Convert a big_index into big_shape to a smaller out_index into shape following broadcasting rules.\n",
        "     In this case it may be larger or with more dimensions than the shape given.\n",
        "     Additional dimensions may need to be mapped to 0 or removed.\n",
        "\n",
        "     Args:\n",
        "        big_index: multidimensional index of bigger tensor\n",
        "        big_shape: tensor shape of bigger tensor\n",
        "        nums_big_dims: number of dimensions in bigger tensor\n",
        "        out_index: multidimensional index of smaller tensor\n",
        "        shape: tensor shape of smaller tensor\n",
        "        num_dims: number of dimensions in smaller tensor\n",
        "\n",
        "     Returns:\n",
        "        None (Fills in out_index)\n",
        "    '''\n",
        "    for i in range(num_dims):\n",
        "        if shape[i] > 1:\n",
        "            out_index[i] = big_index[i + (num_dims_big - num_dims)]\n",
        "        else:\n",
        "            out_index[i] = 0\n"
      ],
      "metadata": {
        "id": "4gcgSCr4KIEV"
      },
      "id": "4gcgSCr4KIEV",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "af01b572-c0aa-41b0-8ba7-b48e3f899978",
      "metadata": {
        "id": "af01b572-c0aa-41b0-8ba7-b48e3f899978"
      },
      "source": [
        "### CUDA matmul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "6dde8ea4-25c3-48fd-97d3-7a0d375dcd73",
      "metadata": {
        "id": "6dde8ea4-25c3-48fd-97d3-7a0d375dcd73"
      },
      "outputs": [],
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n",
        "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (r>=h || c>=w) return;\n",
        "    float o = 0;\n",
        "    for (int i = 0; i<k; ++i) o += m[r*k+i] * n[i*w+c];\n",
        "    out[r*w+c] = o;\n",
        "}\n",
        "\n",
        "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h = m.size(0);\n",
        "    int w = n.size(1);\n",
        "    int k = m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "\n",
        "    dim3 tpb(16,16);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_k<<<blocks, tpb>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "0de6d749-3922-4a30-a00a-60f153d59907",
      "metadata": {
        "id": "0de6d749-3922-4a30-a00a-60f153d59907"
      },
      "outputs": [],
      "source": [
        "cpp_src = \"torch::Tensor matmul(torch::Tensor m, torch::Tensor n);\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "25c0b6ea-c5cf-4bab-9f46-1de103e5ae68",
      "metadata": {
        "id": "25c0b6ea-c5cf-4bab-9f46-1de103e5ae68"
      },
      "outputs": [],
      "source": [
        "module = load_cuda(cuda_src, cpp_src, ['matmul'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "49b0aa26-b9b6-4f5b-8223-5d6afad88bfa",
      "metadata": {
        "id": "49b0aa26-b9b6-4f5b-8223-5d6afad88bfa"
      },
      "outputs": [],
      "source": [
        "m1c,m2c = m1.contiguous().cuda(), m2.contiguous().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "09d45a98-0d7f-4e0e-b704-f979e53550cb",
      "metadata": {
        "id": "09d45a98-0d7f-4e0e-b704-f979e53550cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2a80a4-4637-490f-abe9-318b3e62daae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "torch.isclose(tr,module.matmul(m1c, m2c).cpu(), atol=1e-5).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "5342f1f0-8684-4d6c-814f-ab4b10995ad3",
      "metadata": {
        "id": "5342f1f0-8684-4d6c-814f-ab4b10995ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b707a0e-3dc9-4100-fa9b-fabc32ea8490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.29 ms, sys: 26 µs, total: 6.32 ms\n",
            "Wall time: 5.74 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "source": [
        "%%time\n",
        "res=module.matmul(m1c, m2c).cpu()\n",
        "res.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9bee22-2600-4f6c-a695-e6d9f0ee2177",
      "metadata": {
        "id": "4c9bee22-2600-4f6c-a695-e6d9f0ee2177"
      },
      "source": [
        "### Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "44eb1f44-611d-4270-8054-4cd4217d3305",
      "metadata": {
        "id": "44eb1f44-611d-4270-8054-4cd4217d3305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ed3948-2999-49c7-d9f9-36f49151f826"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "torch.isclose(tr,(m1c@m2c).cpu(), atol=1e-5).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "3d25db36-fad7-4678-9657-cc4efb874276",
      "metadata": {
        "id": "3d25db36-fad7-4678-9657-cc4efb874276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd98fd3-ff38-4069-e9a5-f5266c8d5eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.09 ms ± 69.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 10 _=(m1c@m2c).cpu()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}